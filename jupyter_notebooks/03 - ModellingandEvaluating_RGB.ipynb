{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling and Evaluating - RGB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "To develop, train, and evaluate a machine learning model for image classification, incorporating image augmentation and comprehensive performance analysis through various metrics and visualizations. The objective includes modifying class indices, plotting augmented images, creating and summarizing the model, and saving the trained model. Model performance will be assessed using accuracy, ROC curves, and classification reports, followed by plotting the confusion matrix and saving the evaluation results. The final output will also involve making predictions on a random image file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "* Images are taken from the test, train, validation folders and their subfolders.\n",
    "```\n",
    "└───inputs/ \n",
    "    └───potato_disease_dataset/ \n",
    "        ├───test/\n",
    "        │   ├───healthy\n",
    "        │   ├───early_blight\n",
    "        │   └───late_blight                   \n",
    "        ├───train/\n",
    "        │   ├───healthy\n",
    "        │   ├───early_blight\n",
    "        │   └───late_blight          \n",
    "        └───validation/\n",
    "            ├───healthy\n",
    "            ├───early_blight\n",
    "            └───late_blight               \n",
    "```\n",
    "* Image shape embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "- Image augmentation.\n",
    "    - Plot augmented images for each dataset.\n",
    "- Modify class indices to alter prediction in labels.\n",
    "- Create a machine learning model and display its summary.\n",
    "    - Train the model.\n",
    "    - Save the model.\n",
    "    - Plot the learning curve to show model performance.\n",
    "        - Model A - generate separate plots for accuracy and loss.\n",
    "        - Model B - create a comprehensive model history plot.\n",
    "        - Model C - visualize model history using Plotly.\n",
    "- Evaluate the model using a saved file.\n",
    "    - Calculate accuracy.\n",
    "    - Plot the ROC curve.\n",
    "    - Generate a general classification report.\n",
    "    - Generate a classification report including macro average and weighted average.\n",
    "    - Plot the confusion matrix.\n",
    "    - Save the evaluation results in a pickle file.\n",
    "- Predict on a random image file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating system functionality\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Plotting and visualization\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "\n",
    "# Scikit-learn for evaluation metrics\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the notebooks are within a subfolder, we will need to change the working directory when running the notebook in the editor.\n",
    "\n",
    "We need to change the working directory from its current folder to its parent folder.\n",
    "* We access the current directory with `os.getcwd()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* `os.path.dirname()` gets the parent directory\n",
    "* `os.chir()` defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set input directory\n",
    "Set train, validation and test paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/potato_disease_dataset'\n",
    "train_path = my_data_dir + '/train' \n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'\n",
    "\n",
    "print(\"Train path:\", train_path)\n",
    "print(\"Validation path:\", val_path)\n",
    "print(\"Test path:\", test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the version number below to change output dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v3'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print('Labels for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import saved image shape embedding\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment training image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment validation image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='categorical',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment test image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot augmented datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot augmented datasets\n",
    "def plot_augmented_images(dataset, title):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6, 6))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            img, label = dataset.next()\n",
    "            print(img.shape)\n",
    "            axes[i, j].imshow(img[0])\n",
    "            axes[i, j].axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot augmented training image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmented training image set\n",
    "plot_augmented_images(train_set, \"Augmented Training Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot augmented validation image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmented validation image set\n",
    "plot_augmented_images(validation_set, \"Augmented Validation Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot augmented test image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmented test image set\n",
    "plot_augmented_images(test_set, \"Augmented Test Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=image_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Third Convolutional Layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Flatten the layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(3, activation='softmax'))  # Assuming 3 classes for potato leaf diseases\n",
    "\n",
    "# Summary of the custom model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define model checkpoint callback\n",
    "checkpoint = ModelCheckpoint(f\"{file_path}/best_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Define the learning rate reduction callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "        train_set,\n",
    "        epochs=50,\n",
    "        validation_data=validation_set,\n",
    "        callbacks=[early_stopping, checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(f\"{file_path}/best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning Curve - A\n",
    "This cell creates and saves plots of the training and validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.set_style(\"whitegrid\")\n",
    "losses[['loss', 'val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "# Save the plot of training and validation loss\n",
    "plt.savefig(f'{file_path}/curve_a_model_training_losses.png', bbox_inches='tight', dpi=150)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "# Save the plot of training and validation accuracy\n",
    "plt.savefig(f'{file_path}/curve_a_model_training_acc.png', bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning Curve - B\n",
    "This cell generates and saves a single combined plot of all training and validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation metrics together\n",
    "pd.DataFrame(model.history.history).plot(figsize=(8, 5))\n",
    "\n",
    "# Save the combined plot of all training metrics\n",
    "plt.savefig(f'{file_path}/curve_b_model_loss_acc.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning Curve - C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates an interactive plot with Plotly to show training and validation loss and accuracy on a dual y-axis, and saves the plot as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add validation loss trace to the plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=model.history.history['val_loss'], name=\"val_loss\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Add training loss trace to the plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=model.history.history['loss'], name=\"loss\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Add validation accuracy trace to the plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=model.history.history['val_accuracy'], name=\"val accuracy\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add training accuracy trace to the plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=model.history.history['accuracy'], name=\"accuracy\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Update layout with title and axis labels\n",
    "fig.update_layout(\n",
    "    title_text=\"Loss/Accuracy of Model\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Epoch\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"<b>primary</b> Loss\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"<b>secondary</b> Accuracy\", secondary_y=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800, \n",
    "    height=500, \n",
    "    )\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model\n",
    "Loads the trained and saved model from the specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(f\"{file_path}/best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(test_set)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy and generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the test set iterator, calculates the true labels, and generates predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the test set iterator\n",
    "test_set.reset()\n",
    "\n",
    "# Generate predictions\n",
    "y_true = test_set.classes\n",
    "y_pred = best_model.predict(test_set, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate classification report - A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates and prints a standard classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_report = classification_report(y_true, y_pred_classes, target_names=labels)\n",
    "print(\"Classification Report for Model A:\\n\", general_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate classification report - B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a classification report and visualizes it as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_heatmap = classification_report(y_true, y_pred_classes, target_names=labels, output_dict=True)\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(pd.DataFrame(classification_report_heatmap).iloc[:-1, :].T, annot=True, cmap=\"Blues\", cbar=False, linewidths=1)\n",
    "plt.title('Classification Report')\n",
    "plt.savefig(f'{file_path}/classification_report_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots and saves the ROC curve for each class in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_rate = {}\n",
    "false_positive_rate = {}\n",
    "roc_auc = {}\n",
    "for i, label in enumerate(labels):\n",
    "    false_positive_rate[label], true_positive_rate[label], _ = roc_curve(y_true == i, y_pred[:, i])\n",
    "    roc_auc[label] = auc(false_positive_rate[label], true_positive_rate[label])\n",
    "\n",
    "plt.figure()\n",
    "for label in labels:\n",
    "    plt.plot(false_positive_rate[label], true_positive_rate[label], label=f'ROC curve (area = {roc_auc[label]:.2f}) for {label}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'{file_path}/roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plots and saves the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig(f'{file_path}/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the evaluation results in a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the evaluation results, including accuracy, classification reports, and the confusion matrix, into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"general_report\": general_report,\n",
    "    \"classification_report_heatmap\": classification_report_heatmap,\n",
    "    \"confusion_matrix\": confusion_matrix,\n",
    "    \"roc_curve\": {\n",
    "    \"true_positive_rate\": true_positive_rate,\n",
    "    \"false_positive_rate\": false_positive_rate,\n",
    "    \"roc_auc\": roc_auc\n",
    "}\n",
    "}\n",
    "joblib.dump(evaluation_results, f\"{file_path}/evaluation_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random image from the test set\n",
    "label = random.choice(labels)\n",
    "image_path = os.path.join(test_path, label)\n",
    "image_file = random.choice(os.listdir(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "pil_image = load_img(os.path.join(image_path, image_file), target_size=image_shape[:2], color_mode='rgb')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "plt.imshow(pil_image)\n",
    "plt.title(f'Random Image from {label}')\n",
    "plt.show()\n",
    "\n",
    "# Convert the image to an array and preprocess it\n",
    "my_image = img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0) / 255.0\n",
    "print(my_image.shape)\n",
    "\n",
    "# Predict class probabilities\n",
    "pred_proba = best_model.predict(my_image)\n",
    "\n",
    "# Map predicted class index to class label\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class_index = np.argmax(pred_proba)\n",
    "pred_class = target_map[pred_class_index]\n",
    "pred_proba = pred_proba[0][pred_class_index]\n",
    "\n",
    "print(f'Predicted Probability: {pred_proba}')\n",
    "print(f'Predicted Class: {pred_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
